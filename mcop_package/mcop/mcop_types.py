"""
M-COP v3.1 Core Types and Data Structures

This module defines the fundamental data structures used throughout the
M-COP (Meta-Cognitive Operating Protocol) reasoning system.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from enum import Enum, auto
from abc import ABC, abstractmethod
import uuid
from datetime import datetime


class ReasoningMode(Enum):
    """
    The four fundamental reasoning modes in M-COP.
    These are domain-agnostic and map to specific modes in each domain.
    """
    CAUSAL = auto()        # Mechanistic/cause-effect reasoning (PHYSICS in ARC)
    STRUCTURAL = auto()    # Pattern/architecture reasoning (ATOMIC in ARC)
    SELECTIVE = auto()     # Filtering/pruning reasoning (ENTROPIC in ARC)
    COMPOSITIONAL = auto() # Multi-step synthesis (COMPOSITIONAL in ARC)


class EpistemicState(Enum):
    """Epistemic states for hypothesis tracking."""
    SEED = auto()          # Initial hypothesis
    GROWING = auto()       # Being developed through chaining
    VALIDATED = auto()     # Passed intermediate validation
    PRUNED = auto()        # Eliminated by evidence
    SYNTHESIZED = auto()   # Merged into final solution


@dataclass
class Evidence:
    """
    A piece of evidence supporting or refuting a hypothesis.
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    content: str = ""
    source: str = ""
    evidence_type: str = ""  # Domain-specific (e.g., 'RCT', 'case_study', 'experiment')
    weight: float = 0.5     # Base weight from evidence hierarchy
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __repr__(self):
        return f"Evidence({self.id}: {self.content[:50]}... weight={self.weight:.2f})"


@dataclass
class Hypothesis:
    """
    A hypothesis in the M-COP reasoning system.
    Hypotheses are generated by reasoning modes and refined through mycelial chaining.
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    content: str = ""
    mode: ReasoningMode = ReasoningMode.CAUSAL
    state: EpistemicState = EpistemicState.SEED
    confidence: float = 0.5
    grounding_index: float = 0.0
    evidence: List[Evidence] = field(default_factory=list)
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)
    iteration: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)

    def add_evidence(self, evidence: Evidence):
        """Add evidence and update grounding index."""
        self.evidence.append(evidence)
        self._update_grounding()

    def _update_grounding(self):
        """Recalculate grounding index based on evidence."""
        if not self.evidence:
            self.grounding_index = 0.0
            return

        total_weight = sum(e.weight for e in self.evidence)
        self.grounding_index = min(1.0, total_weight / len(self.evidence))

    def __repr__(self):
        return (f"Hypothesis({self.id}: {self.content[:40]}... "
                f"conf={self.confidence:.2f}, ground={self.grounding_index:.2f})")


@dataclass
class ReasoningChain:
    """
    A chain of reasoning steps (mycelial chain).
    Represents the recursive hypothesis refinement process.
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    hypotheses: List[Hypothesis] = field(default_factory=list)
    root_hypothesis_id: Optional[str] = None
    depth: int = 0
    max_depth: int = 10
    is_complete: bool = False
    final_synthesis: Optional[str] = None
    total_grounding: float = 0.0

    def add_hypothesis(self, hypothesis: Hypothesis):
        """Add a hypothesis to the chain."""
        self.hypotheses.append(hypothesis)
        self.depth = max(self.depth, hypothesis.iteration)
        self._update_total_grounding()

    def _update_total_grounding(self):
        """Calculate aggregate grounding for the chain."""
        if not self.hypotheses:
            self.total_grounding = 0.0
            return

        active = [h for h in self.hypotheses if h.state != EpistemicState.PRUNED]
        if active:
            self.total_grounding = sum(h.grounding_index for h in active) / len(active)

    def get_active_hypotheses(self) -> List[Hypothesis]:
        """Get non-pruned hypotheses."""
        return [h for h in self.hypotheses if h.state != EpistemicState.PRUNED]

    def __repr__(self):
        return f"ReasoningChain({self.id}: depth={self.depth}, hypotheses={len(self.hypotheses)})"


@dataclass
class Problem:
    """
    A problem to be solved by M-COP.
    Domain-agnostic representation of any reasoning task.
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    description: str = ""
    domain: str = "general"
    context: Dict[str, Any] = field(default_factory=dict)
    constraints: List[str] = field(default_factory=list)
    success_criteria: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __repr__(self):
        return f"Problem({self.id}: {self.description[:50]}...)"


@dataclass
class Solution:
    """
    A solution produced by M-COP.
    Contains the answer, reasoning chain, and epistemic metadata.
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    problem_id: str = ""
    content: str = ""
    confidence: float = 0.0
    grounding_index: float = 0.0
    reasoning_chains: List[ReasoningChain] = field(default_factory=list)
    evidence_chain: List[Evidence] = field(default_factory=list)
    alternative_solutions: List['Solution'] = field(default_factory=list)
    key_uncertainties: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convert solution to dictionary for output."""
        return {
            'solution': self.content,
            'confidence': f"{self.confidence * 100:.1f}%",
            'grounding_index': f"{self.grounding_index:.2f}",
            'evidence_chain': [
                {'content': e.content, 'source': e.source, 'weight': e.weight}
                for e in self.evidence_chain
            ],
            'alternatives': [
                {'content': alt.content, 'confidence': f"{alt.confidence * 100:.1f}%"}
                for alt in self.alternative_solutions
            ],
            'key_uncertainties': self.key_uncertainties
        }

    def __repr__(self):
        return (f"Solution({self.id}: {self.content[:40]}... "
                f"conf={self.confidence:.2f}, ground={self.grounding_index:.2f})")


@dataclass
class MCOPContext:
    """
    The complete context for an M-COP reasoning session.
    Following the stateless execution harness pattern, this holds ALL state.
    """
    problem: Problem
    hypotheses: Dict[str, Hypothesis] = field(default_factory=dict)
    chains: Dict[str, ReasoningChain] = field(default_factory=dict)
    evidence_pool: List[Evidence] = field(default_factory=list)
    current_iteration: int = 0
    max_iterations: int = 10
    diversity_threshold: float = 0.3  # Minimum diversity to preserve
    grounding_threshold: float = 0.4  # Minimum grounding to proceed
    confidence_threshold: float = 0.6  # Minimum confidence for solution

    def add_hypothesis(self, hypothesis: Hypothesis) -> str:
        """Add hypothesis to context and return its ID."""
        self.hypotheses[hypothesis.id] = hypothesis
        return hypothesis.id

    def add_chain(self, chain: ReasoningChain) -> str:
        """Add reasoning chain to context and return its ID."""
        self.chains[chain.id] = chain
        return chain.id

    def get_hypothesis(self, hypothesis_id: str) -> Optional[Hypothesis]:
        """Retrieve hypothesis by ID."""
        return self.hypotheses.get(hypothesis_id)

    def get_active_hypotheses(self) -> List[Hypothesis]:
        """Get all non-pruned hypotheses."""
        return [h for h in self.hypotheses.values() if h.state != EpistemicState.PRUNED]